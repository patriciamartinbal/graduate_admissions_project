{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROYECTO OPEN DATA II: MEJORAS AL MODELO\n",
    "En esta segunda parte de la entrega, le aplicamos mejoras al modelo trabajado en la primera parte. \n",
    "Técnicas empleadas:\n",
    "* Extracción de características y PCA\n",
    "* Hyper-tunning de parámentros\n",
    "* Grid search\n",
    "\n",
    "Procedemos con los mismos pasos que en la primera parte de implementación del algoritmo de regresión lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate();\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Serial No.: int, GRE Score: int, TOEFL Score: int, University Rating: int, SOP: double, LOR : double, CGPA: double, Research: int, Chance of Admit : double]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = sqlContext.read.format(\"com.databricks.spark.csv\").options(header='true',inferschema='true').load(\"Admission_Predict.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"Serial No.\", \"Serial No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Serial No: integer (nullable = true)\n",
      " |-- GRE Score: integer (nullable = true)\n",
      " |-- TOEFL Score: integer (nullable = true)\n",
      " |-- University Rating: integer (nullable = true)\n",
      " |-- SOP: double (nullable = true)\n",
      " |-- LOR : double (nullable = true)\n",
      " |-- CGPA: double (nullable = true)\n",
      " |-- Research: integer (nullable = true)\n",
      " |-- Chance of Admit : double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transData(data):\n",
    "    return data.rdd.map(lambda r: [Vectors.dense(r[:-1]),r[-1]]).toDF(['features','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[1.0,337.0,118.0,...| 0.92|\n",
      "|[2.0,324.0,107.0,...| 0.76|\n",
      "|[3.0,316.0,104.0,...| 0.72|\n",
      "|[4.0,322.0,110.0,...|  0.8|\n",
      "|[5.0,314.0,103.0,...| 0.65|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed= transData(df)\n",
    "transformed.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementación del algorítmo PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression \n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import VectorIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "#df = spark.createDataFrame(data,[\"features\"])\n",
    "model = PCA(k=2, inputCol=\"features\", outputCol=\"pca_features\").fit(transformed)\n",
    "data = model.transform(transformed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|            features|label|        pca_features|\n",
      "+--------------------+-----+--------------------+\n",
      "|[1.0,337.0,118.0,...| 0.92|[3.24875991995343...|\n",
      "|[2.0,324.0,107.0,...| 0.76|[2.03427489018224...|\n",
      "|[3.0,316.0,104.0,...| 0.72|[0.92834004552377...|\n",
      "|[4.0,322.0,110.0,...|  0.8|[0.03445640395570...|\n",
      "|[5.0,314.0,103.0,...| 0.65|[-1.1026673565109...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Split the data into training and test sets (40% held out for testing)\n",
    "(trainingData, testData) = transformed.randomSplit([0.6, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[1.0,337.0,118.0,...| 0.92|\n",
      "|[5.0,314.0,103.0,...| 0.65|\n",
      "|[9.0,302.0,102.0,...|  0.5|\n",
      "|[12.0,327.0,111.0...| 0.84|\n",
      "|[13.0,328.0,112.0...| 0.78|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[2.0,324.0,107.0,...| 0.76|\n",
      "|[3.0,316.0,104.0,...| 0.72|\n",
      "|[4.0,322.0,110.0,...|  0.8|\n",
      "|[6.0,330.0,115.0,...|  0.9|\n",
      "|[7.0,321.0,109.0,...| 0.75|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingData.show(5)\n",
    "testData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LinearRegression class\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "# Define LinearRegression algorithm\n",
    "lr = LinearRegression(maxIter=10, regParam=0.01, elasticNetParam=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[model, lr])\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelsummary(model):\n",
    "    import numpy as np\n",
    "    Summary=model.summary\n",
    "    print (\"##\",'---')\n",
    "    print (\"##\",\"Mean squared error: % .6f\" \\\n",
    "           % Summary.meanSquaredError, \", RMSE: % .6f\" \\\n",
    "           % Summary.rootMeanSquaredError )\n",
    "    print (\"##\",\"Multiple R-squared: %f\" % Summary.r2, \", \\\n",
    "    Total iterations: %i\"% Summary.totalIterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## ---\n",
      "## Mean squared error:  0.003143 , RMSE:  0.056062\n",
      "## Multiple R-squared: 0.848034 ,     Total iterations: 11\n"
     ]
    }
   ],
   "source": [
    "modelsummary(model.stages[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------------+\n",
      "|            features|label|        prediction|\n",
      "+--------------------+-----+------------------+\n",
      "|[1.0,337.0,118.0,...| 0.92|0.9161729400221594|\n",
      "|[2.0,324.0,107.0,...| 0.76|0.7786370965160796|\n",
      "|[5.0,314.0,103.0,...| 0.65|0.6251059807902062|\n",
      "|[7.0,321.0,109.0,...| 0.75|0.6943647915557778|\n",
      "|[9.0,302.0,102.0,...|  0.5| 0.549662077885811|\n",
      "+--------------------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select example rows to display.\n",
    "predictions.select(\"features\",\"label\",\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.061483\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Select (prediction, true label) and compute test error \n",
    "evaluator = RegressionEvaluator(labelCol=\"label\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can also check the 𝑅2 value for the test data:\n",
    "y_true = predictions.select(\"label\").toPandas()\n",
    "y_pred = predictions.select(\"prediction\").toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.8092971528076566\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "r2_score = sklearn.metrics.r2_score(y_true, y_pred) \n",
    "print('r2_score: {0}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mejora del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.tuning as tune\n",
    "import pyspark.ml.classification as cl\n",
    "import pyspark.ml.evaluation as ev\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "linear = LinearRegression(labelCol='label',featuresCol = 'pca_features')\n",
    "grid = tune.ParamGridBuilder().addGrid(linear.maxIter, [2, 9, 30]).addGrid(linear.regParam, [0.01, 0.05, 0.3]).addGrid(linear.elasticNetParam, [0.09, 0.04, 0.8]).build()\n",
    "\n",
    "evaluator = ev.BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = tune.CrossValidator(estimator=linear, estimatorParamMaps=grid, evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[model])\n",
    "model = pipeline.fit(trainingData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel = cv.fit(model.transform(trainingData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.869215291750503\n",
      "0.9853605463577588\n"
     ]
    }
   ],
   "source": [
    "data_train = model.transform(testData)\n",
    "results = cvModel.transform(data_train)\n",
    "\n",
    "print(evaluator.evaluate(results, {evaluator.metricName: 'areaUnderROC'}))\n",
    "print(evaluator.evaluate(results, {evaluator.metricName: 'areaUnderPR'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'maxIter': 9}, {'regParam': 0.01}, {'elasticNetParam': 0.09}],\n",
       " 0.9321698732735655)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [\n",
    "    (\n",
    "        [\n",
    "            {key.name: paramValue} \n",
    "            for key, paramValue \n",
    "            in zip(\n",
    "                params.keys(), \n",
    "                params.values())\n",
    "        ], metric\n",
    "    ) \n",
    "    for params, metric \n",
    "    in zip(\n",
    "        cvModel.getEstimatorParamMaps(), \n",
    "        cvModel.avgMetrics\n",
    "    )\n",
    "]\n",
    "\n",
    "sorted(results, key=lambda el: el[1], reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param (MaxIter):  9\n"
     ]
    }
   ],
   "source": [
    "print ('Best Param (MaxIter): ', cvModel.bestModel._java_obj.getMaxIter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param (RegParam):  0.01\n"
     ]
    }
   ],
   "source": [
    "print ('Best Param (RegParam): ', cvModel.bestModel._java_obj.getRegParam())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param (ElasticNetParam):  0.09\n"
     ]
    }
   ],
   "source": [
    "print ('Best Param (ElasticNetParam): ', cvModel.bestModel._java_obj.getElasticNetParam())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracción de caracteristicas y PCA (reducción de dimensinalidad)**\n",
    "\n",
    "PCA es una técnica que trata de reducir el número de dimensiones (variables) de un conjunto de datos intentando, a su vez, conservar la mayor cantidad de información. Es una técnica extremadamente útil en el análisis exploratorio de datos cuando se tiene demasiada información (muchas dimensiones, variables) y no se puede analizar correctamente la información.\n",
    "\n",
    "Para seleccionar las variables más relevante a la hora de hacer predicciones utilizamos el selector Chi-Cuadrado.\n",
    "\n",
    "En nuestro caso, vamos extraer las dos variables que más peso tengan en cuanto a utilidad de la información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChiSqSelector output with top 2 features selected\n",
      "+--------------------+-----+--------------------+----------------+\n",
      "|            features|label|        pca_features|selectedFeatures|\n",
      "+--------------------+-----+--------------------+----------------+\n",
      "|[1.0,337.0,118.0,...| 0.92|[3.24875991995343...|   [337.0,118.0]|\n",
      "|[2.0,324.0,107.0,...| 0.76|[2.03427489018224...|   [324.0,107.0]|\n",
      "|[3.0,316.0,104.0,...| 0.72|[0.92834004552377...|   [316.0,104.0]|\n",
      "|[4.0,322.0,110.0,...|  0.8|[0.03445640395570...|   [322.0,110.0]|\n",
      "|[5.0,314.0,103.0,...| 0.65|[-1.1026673565109...|   [314.0,103.0]|\n",
      "|[6.0,330.0,115.0,...|  0.9|[-1.8424081105850...|   [330.0,115.0]|\n",
      "|[7.0,321.0,109.0,...| 0.75|[-2.9827444301870...|   [321.0,109.0]|\n",
      "|[8.0,308.0,101.0,...| 0.68|[-4.1748594605740...|   [308.0,101.0]|\n",
      "|[9.0,302.0,102.0,...|  0.5|[-5.2306601034426...|   [302.0,102.0]|\n",
      "|[10.0,323.0,108.0...| 0.45|[-5.9708511040333...|   [323.0,108.0]|\n",
      "|[11.0,325.0,106.0...| 0.52|[-6.9658918293670...|   [325.0,106.0]|\n",
      "|[12.0,327.0,111.0...| 0.84|[-7.9041311459009...|   [327.0,111.0]|\n",
      "|[13.0,328.0,112.0...| 0.78|[-8.8863864187354...|   [328.0,112.0]|\n",
      "|[14.0,307.0,109.0...| 0.62|[-10.118781200409...|   [307.0,109.0]|\n",
      "|[15.0,311.0,104.0...| 0.61|[-11.119985853883...|   [311.0,104.0]|\n",
      "|[16.0,314.0,105.0...| 0.54|[-12.082552318854...|   [314.0,105.0]|\n",
      "|[17.0,317.0,107.0...| 0.66|[-13.036210499939...|   [317.0,107.0]|\n",
      "|[18.0,319.0,106.0...| 0.65|[-14.024233715894...|   [319.0,106.0]|\n",
      "|[19.0,318.0,110.0...| 0.63|[-15.002724580234...|   [318.0,110.0]|\n",
      "|[20.0,303.0,102.0...| 0.62|[-16.213222810399...|   [303.0,102.0]|\n",
      "+--------------------+-----+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import ChiSqSelector\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "selector = ChiSqSelector(numTopFeatures=2, featuresCol=\"features\",\n",
    "                             outputCol=\"selectedFeatures\", labelCol=\"label\")\n",
    "\n",
    "result = selector.fit(data).transform(data)\n",
    "\n",
    "print(\"ChiSqSelector output with top %d features selected\" % selector.getNumTopFeatures())\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos que los GRE y TOEFL scores son los más importantes respectivamente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
